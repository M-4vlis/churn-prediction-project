# Churn Prediction Project

Este projeto tem como objetivo prever o cancelamento de clientes com base em seus comportamentos, caracterÃ­sticas demogrÃ¡ficas e interaÃ§Ãµes com a empresa. A ideia Ã© usar esse conhecimento para **reduzir churn**, **aumentar retenÃ§Ã£o** e tomar **decisÃµes estratÃ©gicas de negÃ³cio**.

---

## Estrutura do Projeto

```bash
churn-prediction-project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Dados originais
â”‚   â””â”€â”€ processed/         # Dados limpos e transformados
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 1_EDA.ipynb        # AnÃ¡lise exploratÃ³ria de dados
â”œâ”€â”€ outputs/               # Imagens, grÃ¡ficos e artefatos gerados
â”œâ”€â”€ src/                   # Scripts Python para reutilizaÃ§Ã£o
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ EDA.md             # RelatÃ³rio de insights do EDA
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ cancelamentos.csv      # Dataset original
```

## ğŸ“ Dataset

O dataset contÃ©m informaÃ§Ãµes de 881.666 clientes, com variÃ¡veis relacionadas a:

    Demografia (idade, sexo)

    Comportamento (frequÃªncia de uso, atraso, ligaÃ§Ãµes)

    Tipo de assinatura e contrato

    InteraÃ§Ãµes com o call center

    Gasto total

    Coluna alvo: cancelou (1 = cancelou, 0 = manteve)

## AnÃ¡lise ExploratÃ³ria (EDA)

A EDA foi realizada no notebook [1_EDA.ipynb](1_EDA.ipynb), e os principais insights foram organizados no relatÃ³rio [docs/EDA.md](docs/EDA.md).
 Highlights:

    100% dos clientes com assinatura mensal cancelam

    Clientes que ligam mais de 4x para o call center sempre cancelam

    Acima de 20 dias de atraso, a taxa de churn Ã© total

    Jovens (<20) e idosos (>50) tÃªm maiores taxas de cancelamento

    O pÃºblico feminino apresenta maior tendÃªncia ao churn

## ğŸ§° Tecnologias Utilizadas

- Python 3.12.7
- Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, Imbalanced-learn
- Jupyter Notebooks
- Streamlit
- Conda (ambiente virtual)
- Git + GitHub

âœ… Feature Engineering realizada com encoding, balanceamento e padronizaÃ§Ã£o dos dados

## Modelagem Preditiva

A modelagem foi feita em duas abordagens distintas:

### Abordagem A â€” Dataset Original
Utilizamos os dados como estavam, com alta proporÃ§Ã£o de clientes cancelando (â‰ˆ70%). Isso nos permite observar o comportamento dos modelos quando o churn Ã© dominante.

### Abordagem B â€” Dataset Simulado com Churn â‰ˆ 30%
Criamos uma versÃ£o mais realista da base, simulando uma situaÃ§Ã£o de mercado onde a maioria dos clientes permanece. Essa abordagem visa avaliar o desempenho dos modelos em cenÃ¡rios mais alinhados com a realidade de negÃ³cios.

> âš ï¸ Nota: A base original apresenta uma distribuiÃ§Ã£o invertida (mais clientes cancelam do que permanecem). Veja como isso foi tratado no [relatÃ³rio de EDA](docs/EDA.md#consideraÃ§Ã£o-estratÃ©gica-distribuiÃ§Ã£o-do-churn).

Ambas as versÃµes foram testadas com os seguintes modelos:
- RegressÃ£o LogÃ­stica
- Ãrvore de DecisÃ£o
- Random Forest
- Gradient Boosting
- SVM

As mÃ©tricas avaliadas foram:
- AcurÃ¡cia
- F1-score
- ROC AUC
- Matriz de ConfusÃ£o

---

### ObservaÃ§Ãµes sobre performance

> âš¡ Devido ao alto custo computacional do `SVC` tradicional, optamos por utilizar o `SGDClassifier` com funÃ§Ã£o de perda `hinge`, que implementa um classificador linear semelhante ao SVM, porÃ©m muito mais eficiente em grandes volumes de dados.

---

### AutomaÃ§Ã£o e ModularizaÃ§Ã£o

Foi criado um script `src/train.py` para permitir o reuso e treinamento automÃ¡tico dos modelos, fora do ambiente Jupyter. Isso permite escalar o processo de forma eficiente, e tambÃ©m integra com pipelines futuros de deploy.

Para executar:

```bash
python src/train.py
```

### ğŸ† Modelo Final

ApÃ³s testar 5 algoritmos em duas abordagens de dataset (base original e base simulada com 30% de churn), o modelo escolhido para deploy foi:

**Random Forest Classifier**, com performance:

- F1-score: 0.999 (base simulada)
- AcurÃ¡cia: 0.9995
- ROC AUC: 1.000

AlÃ©m da alta performance, o modelo foi escolhido por sua robustez, estabilidade, e boa interpretabilidade via anÃ¡lise de importÃ¢ncia de variÃ¡veis.

O modelo final foi treinado com a base **balanceada via SMOTE** e **ajustada para refletir uma distribuiÃ§Ã£o de churn mais prÃ³xima do mercado real**.

## ğŸ–¥ï¸ Deploy Interativo com Streamlit

Para facilitar a visualizaÃ§Ã£o dos resultados e permitir a utilizaÃ§Ã£o prÃ¡tica do modelo, foi desenvolvido um aplicativo interativo com **Streamlit**.  

O app permite:
- Entrada manual de dados de um cliente
- Upload de um arquivo CSV com mÃºltiplos clientes
- VisualizaÃ§Ã£o das previsÃµes e probabilidades
- Download do resultado em CSV

### â–¶ï¸ Como executar o app

1. Instale os pacotes:

```bash
pip install -r requirements.txt
```

2. Rode o app com:

```bash
streamlit run app/streamlit_app.py
```

3. O navegador serÃ¡ aberto automaticamente em `http://localhost:8501`

---

### ğŸ“ Exemplo de entrada (CSV):

```csv
sexo,tempo_como_cliente,frequencia_uso,ligacoes_callcenter,dias_atraso,total_gasto,meses_ultima_interacao,idade,assinatura_Standard,assinatura_Premium,duracao_contrato_Monthly,duracao_contrato_Quarterly
1,15,12,2,3,1230.50,5,35,1,0,0,1
0,30,8,5,21,760.00,8,58,0,1,1,0
```

### Autor

Mario Pereira | Cientista de Dados em formaÃ§Ã£o

Sempre buscando soluÃ§Ãµes fora da caixa e insights que transformam nÃºmeros em aÃ§Ã£o.

Contatos: [E-mail](mailto:omario.pereira96@gmail.com) â€¢ [LinkedIn](https://www.linkedin.com/in/omario-silva96) â€¢ [GitHub](https://github.com/M-4vlis)