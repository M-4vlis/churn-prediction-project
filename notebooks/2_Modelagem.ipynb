{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a72ee92",
   "metadata": {},
   "source": [
    "# Modelagem Preditiva - Churn Prediction\n",
    "\n",
    "Neste notebook, vamos construir e avaliar modelos de machine learning para prever o cancelamento de clientes com base em seus dados hist√≥ricos.\n",
    "\n",
    "Como o dataset original apresenta uma propor√ß√£o elevada de cancelamentos (ao contr√°rio da realidade da maioria dos neg√≥cios), adotamos **duas abordagens paralelas**:\n",
    "\n",
    "- **Abordagem A:** Usar o dataset original como est√° (com alto √≠ndice de churn).\n",
    "- **Abordagem B:** Simular uma base mais realista, com churn em aproximadamente 30% dos casos.\n",
    "\n",
    "Com isso, buscamos observar o impacto da distribui√ß√£o da vari√°vel alvo no desempenho dos modelos, simulando tamb√©m uma situa√ß√£o mais pr√≥xima do mercado real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec46dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Importa√ß√£o de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77df6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset limpo\n",
    "df = pd.read_csv('../data/raw/cancelamentos.csv')\n",
    "df = df.dropna()  # Garantindo que n√£o tem valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2cfbc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulando cen√°rio mais realista (30% churn, 70% n√£o churn)\n",
    "\n",
    "# 1. Filtrar as duas classes\n",
    "df_churn = df[df['cancelou'] == 1]\n",
    "df_nao_churn = df[df['cancelou'] == 0]\n",
    "\n",
    "# 2. Quantos churners precisamos para que eles representem 30% da base?\n",
    "n_nao_churn = len(df_nao_churn)\n",
    "n_churn_necessario = int((30 / 70) * n_nao_churn)\n",
    "\n",
    "# 3. Sample dos churners baseado nessa quantidade\n",
    "df_churn_amostrado = df_churn.sample(n=n_churn_necessario, random_state=42)\n",
    "\n",
    "# 4. Juntar a base simulada\n",
    "df_simulado = pd.concat([df_churn_amostrado, df_nao_churn]).sample(frac=1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ebcffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o de pr√©-processamento (para ambas as bases)\n",
    "\n",
    "def preparar_dados(df):\n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    # Encoding bin√°rio para 'sexo'\n",
    "    le = LabelEncoder()\n",
    "    df_temp['sexo'] = le.fit_transform(df_temp['sexo'])\n",
    "    \n",
    "    # One-hot encoding para 'assinatura' e 'duracao_contrato'\n",
    "    df_temp = pd.get_dummies(df_temp, columns=['assinatura', 'duracao_contrato'], drop_first=True)\n",
    "    \n",
    "    # Separar X e y\n",
    "    X = df_temp.drop(['cancelou', 'CustomerID'], axis=1)\n",
    "    y = df_temp['cancelou']\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50542757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a fun√ß√£o nas duas bases\n",
    "\n",
    "# Abordagem A - Base original\n",
    "X, y = preparar_dados(df)\n",
    "\n",
    "# Abordagem B - Base simulada com 30% churn\n",
    "X_sim, y_sim = preparar_dados(df_simulado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06576c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando treino e teste\n",
    "\n",
    "# Base original\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Base simulada\n",
    "X_train_sim, X_test_sim, y_train_sim, y_test_sim = train_test_split(\n",
    "    X_sim, y_sim, test_size=0.25, stratify=y_sim, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a86cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanceamento com SMOTE (equilibrando mais as bases de treino)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)           # original\n",
    "X_train_sim_res, y_train_sim_res = sm.fit_resample(X_train_sim, y_train_sim)  # simulado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b90071",
   "metadata": {},
   "source": [
    "## Compara√ß√£o de Modelos\n",
    "\n",
    "A seguir, comparamos 5 algoritmos de classifica√ß√£o aplicados em duas vers√µes da base:\n",
    "\n",
    "- Base original com alta propor√ß√£o de churners.\n",
    "- Base simulada com 30% de churn, mais pr√≥xima do mercado real.\n",
    "\n",
    "As m√©tricas utilizadas foram:\n",
    "- Acur√°cia\n",
    "- F1-score\n",
    "- ROC AUC\n",
    "\n",
    "O objetivo √© entender qual modelo se comporta melhor em diferentes cen√°rios e qual oferece maior capacidade preditiva para problemas reais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os modelos\n",
    "\n",
    "modelos = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"SVM\": SVC(probability=True)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85b4294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando os modelos\n",
    "\n",
    "def avaliar_modelos(modelos, X_train, y_train, X_test, y_test):\n",
    "    resultados = []\n",
    "\n",
    "    for nome, modelo in modelos.items():\n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        acc = modelo.score(X_test, y_test)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        print(f\"\\nüìä Modelo: {nome}\")\n",
    "        print(f\"Acur√°cia: {acc:.3f}\")\n",
    "        print(f\"F1-score: {f1:.3f}\")\n",
    "        print(f\"ROC AUC: {auc:.3f}\")\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "        resultados.append({\n",
    "            \"Modelo\": nome,\n",
    "            \"Acur√°cia\": acc,\n",
    "            \"F1-score\": f1,\n",
    "            \"ROC AUC\": auc\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(resultados).sort_values(by=\"F1-score\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82e249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Modelo: Logistic Regression\n",
      "Acur√°cia: 0.894\n",
      "F1-score: 0.903\n",
      "ROC AUC: 0.958\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.92      0.88     95417\n",
      "         1.0       0.94      0.87      0.90    124998\n",
      "\n",
      "    accuracy                           0.89    220415\n",
      "   macro avg       0.89      0.90      0.89    220415\n",
      "weighted avg       0.90      0.89      0.89    220415\n",
      "\n",
      "\n",
      "üìä Modelo: Decision Tree\n",
      "Acur√°cia: 1.000\n",
      "F1-score: 1.000\n",
      "ROC AUC: 1.000\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     95417\n",
      "         1.0       1.00      1.00      1.00    124998\n",
      "\n",
      "    accuracy                           1.00    220415\n",
      "   macro avg       1.00      1.00      1.00    220415\n",
      "weighted avg       1.00      1.00      1.00    220415\n",
      "\n",
      "\n",
      "üìä Modelo: Random Forest\n",
      "Acur√°cia: 1.000\n",
      "F1-score: 1.000\n",
      "ROC AUC: 1.000\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     95417\n",
      "         1.0       1.00      1.00      1.00    124998\n",
      "\n",
      "    accuracy                           1.00    220415\n",
      "   macro avg       1.00      1.00      1.00    220415\n",
      "weighted avg       1.00      1.00      1.00    220415\n",
      "\n",
      "\n",
      "üìä Modelo: Gradient Boosting\n",
      "Acur√°cia: 0.997\n",
      "F1-score: 0.997\n",
      "ROC AUC: 1.000\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00     95417\n",
      "         1.0       1.00      0.99      1.00    124998\n",
      "\n",
      "    accuracy                           1.00    220415\n",
      "   macro avg       1.00      1.00      1.00    220415\n",
      "weighted avg       1.00      1.00      1.00    220415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avaliando a base original balanceada com SMOTE\n",
    "\n",
    "avaliacao_original = avaliar_modelos(modelos, X_train_res, y_train_res, X_test, y_test)\n",
    "avaliacao_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando a base simulada com 30% de churn\n",
    "\n",
    "avaliacao_simulada = avaliar_modelos(modelos, X_train_sim_res, y_train_sim_res, X_test_sim, y_test_sim)\n",
    "avaliacao_simulada\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn-prediction-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
